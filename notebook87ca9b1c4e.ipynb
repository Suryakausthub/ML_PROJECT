{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10023757,"sourceType":"datasetVersion","datasetId":6172674}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:16:49.692588Z","iopub.execute_input":"2024-11-27T06:16:49.693381Z","iopub.status.idle":"2024-11-27T06:16:50.151230Z","shell.execute_reply.started":"2024-11-27T06:16:49.693343Z","shell.execute_reply":"2024-11-27T06:16:50.150530Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hinditotelugu/FINAL_ML (1).xlsx\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install openpyxl to read Excel files\n!pip install openpyxl\n\n# Step 1: Import Necessary Libraries\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport string\nfrom string import digits\nimport re\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nprint(\"Libraries imported successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:16:50.152739Z","iopub.execute_input":"2024-11-27T06:16:50.153112Z","iopub.status.idle":"2024-11-27T06:16:56.916076Z","shell.execute_reply.started":"2024-11-27T06:16:50.153082Z","shell.execute_reply":"2024-11-27T06:16:56.915371Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/site-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1732688214.627702   16723 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1127 06:16:54.636146419   16723 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1127 06:16:54.636160960   16723 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1127 06:16:54.636164135   16723 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1127 06:16:54.636166467   16723 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1127 06:16:54.636168759   16723 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1127 06:16:54.636171027   16723 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1127 06:16:54.636173281   16723 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1127 06:16:54.636175468   16723 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1127 06:16:54.636177616   16723 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1127 06:16:54.636179775   16723 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1127 06:16:54.636181924   16723 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1127 06:16:54.636184061   16723 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1127 06:16:54.636186197   16723 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1127 06:16:54.636188318   16723 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1127 06:16:54.636190436   16723 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1127 06:16:54.636192575   16723 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1127 06:16:54.636194965   16723 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1127 06:16:54.636197104   16723 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1127 06:16:54.636199257   16723 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1127 06:16:54.636201423   16723 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1127 06:16:54.636203582   16723 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1127 06:16:54.636205723   16723 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1127 06:16:54.636207968   16723 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1127 06:16:54.636210137   16723 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1127 06:16:54.636212230   16723 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1127 06:16:54.636214337   16723 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1127 06:16:54.636216555   16723 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1127 06:16:54.636218745   16723 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1127 06:16:54.636221034   16723 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1127 06:16:54.636224299   16723 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1127 06:16:54.636226557   16723 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1127 06:16:54.636228763   16723 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1127 06:16:54.636230997   16723 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1127 06:16:54.636233172   16723 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1127 06:16:54.636235327   16723 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1127 06:16:54.636237483   16723 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1127 06:16:54.636239594   16723 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1127 06:16:54.636241719   16723 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1127 06:16:54.636243938   16723 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1127 06:16:54.636246097   16723 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1127 06:16:54.636248237   16723 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1127 06:16:54.636250343   16723 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1127 06:16:54.636252501   16723 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1127 06:16:54.636254703   16723 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1127 06:16:54.636257016   16723 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1127 06:16:54.636427022   16723 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD1127 06:16:54.636438768   16723 ev_posix.cc:113]                      Using polling engine: epoll1\nD1127 06:16:54.647349101   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1127 06:16:54.647359216   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1127 06:16:54.647367381   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1127 06:16:54.647370600   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1127 06:16:54.647373968   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1127 06:16:54.647376834   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1127 06:16:54.647403647   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1127 06:16:54.647419413   16723 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1127 06:16:54.647436743   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1127 06:16:54.647462476   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1127 06:16:54.647469794   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1127 06:16:54.647472931   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1127 06:16:54.647476805   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1127 06:16:54.647480013   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1127 06:16:54.647483261   16723 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1127 06:16:54.647486443   16723 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1127 06:16:54.647517646   16723 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1127 06:16:54.649284497   16723 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI1127 06:16:54.664845250   16723 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1127 06:16:54.668672509   16879 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1127 06:16:54.668725418   16879 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1127 06:16:54.675063493   16876 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-11-27T06:16:54.675034832+00:00\"}\n","output_type":"stream"},{"name":"stdout","text":"Libraries imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Step 2: Set up TPU\n\ntry:\n    # Detect TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    # Connect to TPU cluster\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    # Create TPU strategy\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()  # Default strategy\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:16:56.917037Z","iopub.execute_input":"2024-11-27T06:16:56.917514Z","iopub.status.idle":"2024-11-27T06:17:04.217761Z","shell.execute_reply.started":"2024-11-27T06:16:56.917483Z","shell.execute_reply":"2024-11-27T06:17:04.216959Z"}},"outputs":[{"name":"stdout","text":"Running on TPU  \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732688219.565248   16723 service.cc:145] XLA service 0x587afa8c17a0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732688219.565321   16723 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1732688219.565326   16723 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1732688219.565329   16723 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1732688219.565332   16723 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1732688219.565335   16723 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1732688219.565355   16723 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1732688219.565358   16723 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1732688219.565360   16723 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nREPLICAS:  8\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Step 3: Load the Dataset\n\n# List files in the input directory\nprint(\"Files in the input directory:\")\nprint(os.listdir(\"../input\"))\n\n# Adjust the file path according to your dataset\n# Replace 'hinditotelugu' and 'FINAL_ML (1).xlsx' with actual names if different\ndata = pd.read_excel(\"/kaggle/input/hinditotelugu/FINAL_ML (1).xlsx\", names=['HINDI', 'TELUGU'], header=None, skiprows=1)\n\n# Display the first few rows\nprint(\"\\nFirst few rows of the dataset:\")\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:04.218717Z","iopub.execute_input":"2024-11-27T06:17:04.218962Z","iopub.status.idle":"2024-11-27T06:17:05.634953Z","shell.execute_reply.started":"2024-11-27T06:17:04.218937Z","shell.execute_reply":"2024-11-27T06:17:05.633983Z"}},"outputs":[{"name":"stdout","text":"Files in the input directory:\n['hinditotelugu']\n\nFirst few rows of the dataset:\n                                  HINDI  \\\n0                                शीर्षक   \n1             आईडीबीआई पर आरबीआई की नजर   \n2  आज बैंकिंग प्रमुखों से मिलेंगे जेटली   \n3    जडेजा ने एक महत्वपूर्ण विकेट लिया।   \n4    पाकिस्तान की एक और भड़काऊ कार्रवाई   \n\n                                    TELUGU  \n0                                  శీర్షిక  \n1                   ఐడిబిఐపై ఆర్‌బిఐ నజర్‌  \n2    బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ  \n3                కీలక వికెట్ తీసిన జడేజా..  \n4  మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Step 4: Preprocess the Data\n\n# Check for missing values\nprint(\"\\nNumber of missing values in HINDI column:\", data['HINDI'].isnull().sum())\nprint(\"Number of missing values in TELUGU column:\", data['TELUGU'].isnull().sum())\n\n# Drop rows with missing values\ndata = data.dropna(subset=['HINDI', 'TELUGU'])\nprint(\"After dropping missing values, data shape:\", data.shape)\n\n# Remove empty strings\ndata = data[data['HINDI'].str.strip().astype(bool)]\ndata = data[data['TELUGU'].str.strip().astype(bool)]\ndata.reset_index(drop=True, inplace=True)\n\n# Convert all entries to strings\ndata['HINDI'] = data['HINDI'].astype(str)\ndata['TELUGU'] = data['TELUGU'].astype(str)\n\n# Lowercase all characters\ndata['HINDI'] = data['HINDI'].apply(lambda x: x.lower())\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: x.lower())\n\n# Remove quotes\ndata['HINDI'] = data['HINDI'].apply(lambda x: x.replace(\"'\", ''))\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: x.replace(\"'\", ''))\n\n# Remove punctuation\nexclude = set(string.punctuation)\ndata['HINDI'] = data['HINDI'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n\n# Remove digits\nremove_digits = str.maketrans('', '', digits)\ndata['HINDI'] = data['HINDI'].apply(lambda x: x.translate(remove_digits))\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: x.translate(remove_digits))\n\n# Remove extra spaces\ndata['HINDI'] = data['HINDI'].apply(lambda x: x.strip())\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: x.strip())\ndata['HINDI'] = data['HINDI'].apply(lambda x: re.sub(\" +\", \" \", x))\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: re.sub(\" +\", \" \", x))\n\n# Add start and end tokens to target sequences\ndata['TELUGU'] = data['TELUGU'].apply(lambda x: 'START_ ' + x + ' _END')\n\n# Display the preprocessed data\nprint(\"\\nPreprocessed Data:\")\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:05.636899Z","iopub.execute_input":"2024-11-27T06:17:05.637171Z","iopub.status.idle":"2024-11-27T06:17:06.256194Z","shell.execute_reply.started":"2024-11-27T06:17:05.637145Z","shell.execute_reply":"2024-11-27T06:17:06.255387Z"}},"outputs":[{"name":"stdout","text":"\nNumber of missing values in HINDI column: 1\nNumber of missing values in TELUGU column: 0\nAfter dropping missing values, data shape: (21403, 2)\n\nPreprocessed Data:\n                                  HINDI  \\\n0                                शीर्षक   \n1             आईडीबीआई पर आरबीआई की नजर   \n2  आज बैंकिंग प्रमुखों से मिलेंगे जेटली   \n3    जडेजा ने एक महत्वपूर्ण विकेट लिया।   \n4    पाकिस्तान की एक और भड़काऊ कार्रवाई   \n\n                                              TELUGU  \n0                                START_ శీర్షిక _END  \n1                 START_ ఐడిబిఐపై ఆర్‌బిఐ నజర్‌ _END  \n2  START_ బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ _END  \n3                START_ కీలక వికెట్ తీసిన జడేజా _END  \n4  START_ మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్...  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Step 5: Create Vocabulary Dictionaries\n\nall_hindi_words = set()\nfor hin in data['HINDI']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)\n\nall_telugu_words = set()\nfor tel in data['TELUGU']:\n    for word in tel.split():\n        if word not in all_telugu_words:\n            all_telugu_words.add(word)\n\nprint(\"\\nTotal unique Hindi words:\", len(all_hindi_words))\nprint(\"Total unique Telugu words:\", len(all_telugu_words))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:06.257135Z","iopub.execute_input":"2024-11-27T06:17:06.257409Z","iopub.status.idle":"2024-11-27T06:17:06.343928Z","shell.execute_reply.started":"2024-11-27T06:17:06.257382Z","shell.execute_reply":"2024-11-27T06:17:06.343038Z"}},"outputs":[{"name":"stdout","text":"\nTotal unique Hindi words: 16068\nTotal unique Telugu words: 32316\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Step 6: Calculate Sentence Lengths and Filter Sentences\n\ndata['length_hindi_sentence'] = data['HINDI'].apply(lambda x: len(x.split(\" \")))\ndata['length_telugu_sentence'] = data['TELUGU'].apply(lambda x: len(x.split(\" \")))\n\nprint(\"\\nSentence length statistics:\")\nprint(data[['length_hindi_sentence', 'length_telugu_sentence']].describe())\n\n# Set maximum sentence lengths (adjust as needed)\nmax_length_src = 20  # Hindi sentences\nmax_length_tar = 20  # Telugu sentences\n\n# Filter sentences based on length\ndata = data[data['length_hindi_sentence'] <= max_length_src]\ndata = data[data['length_telugu_sentence'] <= max_length_tar]\ndata.reset_index(drop=True, inplace=True)\n\nprint(\"\\nData after filtering based on sentence lengths:\")\nprint(data.head())\nprint(\"Total samples after filtering:\", data.shape[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:06.345090Z","iopub.execute_input":"2024-11-27T06:17:06.345484Z","iopub.status.idle":"2024-11-27T06:17:06.409001Z","shell.execute_reply.started":"2024-11-27T06:17:06.345454Z","shell.execute_reply":"2024-11-27T06:17:06.408194Z"}},"outputs":[{"name":"stdout","text":"\nSentence length statistics:\n       length_hindi_sentence  length_telugu_sentence\ncount           21403.000000            21403.000000\nmean                7.079615                6.328272\nstd                16.366744                1.589870\nmin                 1.000000                3.000000\n25%                 5.000000                5.000000\n50%                 7.000000                6.000000\n75%                 9.000000                7.000000\nmax              2361.000000               14.000000\n\nData after filtering based on sentence lengths:\n                                  HINDI  \\\n0                                शीर्षक   \n1             आईडीबीआई पर आरबीआई की नजर   \n2  आज बैंकिंग प्रमुखों से मिलेंगे जेटली   \n3    जडेजा ने एक महत्वपूर्ण विकेट लिया।   \n4    पाकिस्तान की एक और भड़काऊ कार्रवाई   \n\n                                              TELUGU  length_hindi_sentence  \\\n0                                START_ శీర్షిక _END                      1   \n1                 START_ ఐడిబిఐపై ఆర్‌బిఐ నజర్‌ _END                      5   \n2  START_ బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ _END                      6   \n3                START_ కీలక వికెట్ తీసిన జడేజా _END                      6   \n4  START_ మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్...                      6   \n\n   length_telugu_sentence  \n0                       3  \n1                       5  \n2                       7  \n3                       6  \n4                       7  \nTotal samples after filtering: 21390\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Step 7: Prepare Data for Training\n\n# Sort the unique words to maintain consistency\ninput_words = sorted(list(all_hindi_words))\ntarget_words = sorted(list(all_telugu_words))\n\n# Define the number of unique tokens (+1 for padding)\nnum_encoder_tokens = len(input_words) + 1  # +1 for padding token\nnum_decoder_tokens = len(target_words) + 1  # +1 for padding token\n\n# Create word-to-index and index-to-word dictionaries for Hindi\ninput_token_index = dict([(word, i + 1) for i, word in enumerate(input_words)])\nreverse_input_token_index = dict((i, word) for word, i in input_token_index.items())\n\n# Create word-to-index and index-to-word dictionaries for Telugu\ntarget_token_index = dict([(word, i + 1) for i, word in enumerate(target_words)])\nreverse_target_token_index = dict((i, word) for word, i in target_token_index.items())\n\nprint(\"\\nNumber of unique input tokens (Hindi):\", num_encoder_tokens)\nprint(\"Number of unique output tokens (Telugu):\", num_decoder_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:06.409934Z","iopub.execute_input":"2024-11-27T06:17:06.410226Z","iopub.status.idle":"2024-11-27T06:17:06.470457Z","shell.execute_reply.started":"2024-11-27T06:17:06.410185Z","shell.execute_reply":"2024-11-27T06:17:06.469604Z"}},"outputs":[{"name":"stdout","text":"\nNumber of unique input tokens (Hindi): 16069\nNumber of unique output tokens (Telugu): 32317\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Step 8: Prepare Sequences and Split the Data\n\n# Prepare input sequences\nencoder_input_data = []\nfor input_text in data['HINDI']:\n    encoder_input_data.append([input_token_index.get(word, 0) for word in input_text.split()])\n\n# Prepare decoder input and output sequences\ndecoder_input_data = []\ndecoder_target_data = []\nfor target_text in data['TELUGU']:\n    target_words = target_text.split()\n    decoder_input_data.append([target_token_index.get(word, 0) for word in target_words[:-1]])  # exclude _END token\n    decoder_target_data.append([target_token_index.get(word, 0) for word in target_words[1:]])  # exclude START_ token\n\n# Pad sequences\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nencoder_input_data = pad_sequences(encoder_input_data, maxlen=max_length_src, padding='post')\ndecoder_input_data = pad_sequences(decoder_input_data, maxlen=max_length_tar, padding='post')\ndecoder_target_data = pad_sequences(decoder_target_data, maxlen=max_length_tar, padding='post')\n\n# Convert decoder_target_data to one-hot vectors\ndecoder_target_data_onehot = tf.keras.utils.to_categorical(decoder_target_data, num_classes=num_decoder_tokens)\n\nprint(\"\\nData prepared for training.\")\n\n# Split the data into training and test sets\nX_train_enc, X_test_enc, X_train_dec_inp, X_test_dec_inp, y_train, y_test = train_test_split(\n    encoder_input_data, decoder_input_data, decoder_target_data_onehot, test_size=0.2, random_state=42)\n\nprint(\"\\nTraining and test data sizes:\")\nprint(\"Training data:\", X_train_enc.shape)\nprint(\"Test data:\", X_test_enc.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:17:06.471438Z","iopub.execute_input":"2024-11-27T06:17:06.471697Z","iopub.status.idle":"2024-11-27T06:18:16.107222Z","shell.execute_reply.started":"2024-11-27T06:17:06.471671Z","shell.execute_reply":"2024-11-27T06:18:16.106371Z"}},"outputs":[{"name":"stdout","text":"\nData prepared for training.\n\nTraining and test data sizes:\nTraining data: (17112, 20)\nTest data: (4278, 20)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Step 9: Build the Encoder-Decoder Model\n\nlatent_dim = 256  # Adjust as needed\n\nwith strategy.scope():\n    # Encoder\n    encoder_inputs = tf.keras.layers.Input(shape=(None,), name='encoder_inputs')\n    enc_emb = tf.keras.layers.Embedding(num_encoder_tokens, latent_dim, mask_zero=True, name='encoder_embedding')(encoder_inputs)\n    encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(latent_dim, return_state=True, name='encoder_lstm')(enc_emb)\n    encoder_states = [state_h, state_c]\n\n    # Decoder\n    decoder_inputs = tf.keras.layers.Input(shape=(None,), name='decoder_inputs')\n    dec_emb_layer = tf.keras.layers.Embedding(num_decoder_tokens, latent_dim, mask_zero=True, name='decoder_embedding')\n    dec_emb = dec_emb_layer(decoder_inputs)\n    decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n    decoder_dense = tf.keras.layers.Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n    decoder_outputs = decoder_dense(decoder_outputs)\n\n    # Define the model\n    model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    # Compile the model\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"\\nModel Summary:\")\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:18:16.108243Z","iopub.execute_input":"2024-11-27T06:18:16.108515Z","iopub.status.idle":"2024-11-27T06:18:20.610906Z","shell.execute_reply.started":"2024-11-27T06:18:16.108489Z","shell.execute_reply":"2024-11-27T06:18:20.609995Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1732688296.173942   16723 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nModel Summary:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m4,113,664\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m8,273,152\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m525,312\u001b[0m │ encoder_embeddin… │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m525,312\u001b[0m │ decoder_embeddin… │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m8,305,469\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m32317\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,113,664</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,273,152</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ encoder_embeddin… │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ decoder_embeddin… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,305,469</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32317</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,742,909\u001b[0m (82.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,742,909</span> (82.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,742,909\u001b[0m (82.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,742,909</span> (82.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Step 10: Train the Model\n\nbatch_size = 64  # Adjust as needed (should be a multiple of 8 for TPU)\nepochs = 50  # Adjust as needed\n\n# Since we are using numpy arrays, we can use model.fit directly\nhistory = model.fit([X_train_enc, X_train_dec_inp], y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=([X_test_enc, X_test_dec_inp], y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:18:20.611823Z","iopub.execute_input":"2024-11-27T06:18:20.612074Z","iopub.status.idle":"2024-11-27T06:45:36.036861Z","shell.execute_reply.started":"2024-11-27T06:18:20.612035Z","shell.execute_reply":"2024-11-27T06:45:36.035414Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-27 06:21:26.121865: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.\nI0000 00:00:1732688486.796878   17527 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(15f3aafa88e99087:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/268\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 103ms/step - accuracy: 0.0125 - loss: 10.3828    ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732688496.066927   17527 tpu_compile_op_common.cc:245] Compilation of 15f3aafa88e99087:0:0 with session name  took 9.269339593s and succeeded\nI0000 00:00:1732688496.085307   17527 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(15f3aafa88e99087:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_2097779827705844746\", property.function_library_fingerprint = 6845137501007871305, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,20,;8,20,;8,20,32317,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732688496.085362   17527 tpu_compilation_cache_interface.cc:541] After adding entry for key 15f3aafa88e99087:0:0 with session_name  cache is 1 entries (17416868 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m266/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0491 - loss: 8.5914","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732688513.986525   17532 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(d8d6e9d2ef7625dc:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.0491 - loss: 8.5885","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732688521.633093   17532 tpu_compile_op_common.cc:245] Compilation of d8d6e9d2ef7625dc:0:0 with session name  took 7.646507455s and succeeded\nI0000 00:00:1732688521.647568   17532 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(d8d6e9d2ef7625dc:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_2097779827705844746\", property.function_library_fingerprint = 6845137501007871305, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"3,20,;3,20,;3,20,32317,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732688521.647613   17532 tpu_compilation_cache_interface.cc:541] After adding entry for key d8d6e9d2ef7625dc:0:0 with session_name  cache is 2 entries (33912274 bytes),  marked for eviction 0 entries (0 bytes).\n2024-11-27 06:22:35.263888: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\nI0000 00:00:1732688555.753354   17487 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(65000ba2c889913b:0:0), session_name()\nI0000 00:00:1732688557.888138   17487 tpu_compile_op_common.cc:245] Compilation of 65000ba2c889913b:0:0 with session name  took 2.134734885s and succeeded\nI0000 00:00:1732688557.892835   17487 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(65000ba2c889913b:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_8410191941267949904\", property.function_library_fingerprint = 6081821840311488523, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,20,;8,20,;8,20,32317,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732688557.892872   17487 tpu_compilation_cache_interface.cc:541] After adding entry for key 65000ba2c889913b:0:0 with session_name  cache is 3 entries (40530804 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1732688561.654373   17513 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(bef76304a1e22860:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 252ms/step - accuracy: 0.0491 - loss: 8.5870 - val_accuracy: 0.0513 - val_loss: 8.0019\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732688563.381017   17513 tpu_compile_op_common.cc:245] Compilation of bef76304a1e22860:0:0 with session name  took 1.726608478s and succeeded\nI0000 00:00:1732688563.385427   17513 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(bef76304a1e22860:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_8410191941267949904\", property.function_library_fingerprint = 6081821840311488523, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"7,20,;7,20,;7,20,32317,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732688563.385455   17513 tpu_compilation_cache_interface.cc:541] After adding entry for key bef76304a1e22860:0:0 with session_name  cache is 4 entries (47064310 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.0512 - loss: 7.8613 - val_accuracy: 0.0515 - val_loss: 7.8803\nEpoch 3/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.0514 - loss: 7.6784 - val_accuracy: 0.0518 - val_loss: 7.8026\nEpoch 4/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.0529 - loss: 7.4875 - val_accuracy: 0.0530 - val_loss: 7.7799\nEpoch 5/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0540 - loss: 7.3180 - val_accuracy: 0.0543 - val_loss: 7.6354\nEpoch 6/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0561 - loss: 7.0557 - val_accuracy: 0.0553 - val_loss: 7.6062\nEpoch 7/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0571 - loss: 6.9220 - val_accuracy: 0.0557 - val_loss: 7.5101\nEpoch 8/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 98ms/step - accuracy: 0.0586 - loss: 6.7713 - val_accuracy: 0.0540 - val_loss: 7.5001\nEpoch 9/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.0607 - loss: 6.5766 - val_accuracy: 0.0554 - val_loss: 7.4425\nEpoch 10/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.0641 - loss: 6.3834 - val_accuracy: 0.0552 - val_loss: 7.4267\nEpoch 11/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 100ms/step - accuracy: 0.0655 - loss: 6.2183 - val_accuracy: 0.0581 - val_loss: 7.4144\nEpoch 12/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0674 - loss: 6.0982 - val_accuracy: 0.0574 - val_loss: 7.3916\nEpoch 13/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0725 - loss: 5.8984 - val_accuracy: 0.0564 - val_loss: 7.3972\nEpoch 14/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.0747 - loss: 5.7585 - val_accuracy: 0.0570 - val_loss: 7.3777\nEpoch 15/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.0781 - loss: 5.5503 - val_accuracy: 0.0561 - val_loss: 7.4085\nEpoch 16/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.0811 - loss: 5.3752 - val_accuracy: 0.0575 - val_loss: 7.4166\nEpoch 17/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - accuracy: 0.0830 - loss: 5.3045 - val_accuracy: 0.0563 - val_loss: 7.4465\nEpoch 18/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.0845 - loss: 5.1198 - val_accuracy: 0.0568 - val_loss: 7.4412\nEpoch 19/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.0895 - loss: 4.9282 - val_accuracy: 0.0564 - val_loss: 7.4751\nEpoch 20/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 101ms/step - accuracy: 0.0912 - loss: 4.8660 - val_accuracy: 0.0568 - val_loss: 7.4810\nEpoch 21/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.0951 - loss: 4.7206 - val_accuracy: 0.0578 - val_loss: 7.4987\nEpoch 22/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 101ms/step - accuracy: 0.0995 - loss: 4.5921 - val_accuracy: 0.0566 - val_loss: 7.4951\nEpoch 23/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1013 - loss: 4.4500 - val_accuracy: 0.0574 - val_loss: 7.5460\nEpoch 24/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1057 - loss: 4.3071 - val_accuracy: 0.0572 - val_loss: 7.5367\nEpoch 25/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - accuracy: 0.1115 - loss: 4.1898 - val_accuracy: 0.0565 - val_loss: 7.5699\nEpoch 26/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1157 - loss: 4.0280 - val_accuracy: 0.0548 - val_loss: 7.6278\nEpoch 27/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1171 - loss: 3.9388 - val_accuracy: 0.0569 - val_loss: 7.6068\nEpoch 28/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1240 - loss: 3.7686 - val_accuracy: 0.0562 - val_loss: 7.6272\nEpoch 29/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1284 - loss: 3.6140 - val_accuracy: 0.0565 - val_loss: 7.6432\nEpoch 30/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1342 - loss: 3.4991 - val_accuracy: 0.0563 - val_loss: 7.6748\nEpoch 31/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1383 - loss: 3.4433 - val_accuracy: 0.0563 - val_loss: 7.7105\nEpoch 32/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1441 - loss: 3.2921 - val_accuracy: 0.0559 - val_loss: 7.7742\nEpoch 33/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - accuracy: 0.1488 - loss: 3.2188 - val_accuracy: 0.0555 - val_loss: 7.7700\nEpoch 34/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1565 - loss: 3.1128 - val_accuracy: 0.0543 - val_loss: 7.8156\nEpoch 35/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1593 - loss: 3.0267 - val_accuracy: 0.0539 - val_loss: 7.8180\nEpoch 36/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.1683 - loss: 2.7941 - val_accuracy: 0.0531 - val_loss: 7.8424\nEpoch 37/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1727 - loss: 2.7808 - val_accuracy: 0.0541 - val_loss: 7.8578\nEpoch 38/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1790 - loss: 2.6542 - val_accuracy: 0.0540 - val_loss: 7.9122\nEpoch 39/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1789 - loss: 2.6292 - val_accuracy: 0.0531 - val_loss: 7.9225\nEpoch 40/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.1876 - loss: 2.4769 - val_accuracy: 0.0559 - val_loss: 7.9239\nEpoch 41/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - accuracy: 0.1905 - loss: 2.4732 - val_accuracy: 0.0536 - val_loss: 7.9597\nEpoch 42/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.1990 - loss: 2.3140 - val_accuracy: 0.0525 - val_loss: 8.0285\nEpoch 43/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 104ms/step - accuracy: 0.2058 - loss: 2.2491 - val_accuracy: 0.0522 - val_loss: 8.0424\nEpoch 44/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 102ms/step - accuracy: 0.2067 - loss: 2.2087 - val_accuracy: 0.0516 - val_loss: 8.0580\nEpoch 45/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 104ms/step - accuracy: 0.2107 - loss: 2.0951 - val_accuracy: 0.0538 - val_loss: 8.0589\nEpoch 46/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 103ms/step - accuracy: 0.2183 - loss: 1.9661 - val_accuracy: 0.0511 - val_loss: 8.1237\nEpoch 47/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 104ms/step - accuracy: 0.2179 - loss: 1.9171 - val_accuracy: 0.0533 - val_loss: 8.0972\nEpoch 48/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - accuracy: 0.2214 - loss: 1.8956 - val_accuracy: 0.0539 - val_loss: 8.1353\nEpoch 49/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 105ms/step - accuracy: 0.2272 - loss: 1.7803 - val_accuracy: 0.0532 - val_loss: 8.1696\nEpoch 50/50\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 105ms/step - accuracy: 0.2341 - loss: 1.7316 - val_accuracy: 0.0516 - val_loss: 8.1903\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Step 11: Save the Model Weights\n\nimport tensorflow as tf\n\n# Explicitly specify the CPU device for saving weights\nwith tf.device('/CPU:0'):\n    model.save_weights('nmt_weights.weights.h5')\n    print(\"\\nModel weights saved as 'nmt_weights.weights.h5'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:45:36.042106Z","iopub.execute_input":"2024-11-27T06:45:36.042455Z","iopub.status.idle":"2024-11-27T06:45:37.397008Z","shell.execute_reply.started":"2024-11-27T06:45:36.042422Z","shell.execute_reply":"2024-11-27T06:45:37.395375Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Explicitly specify the CPU device for saving weights\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnmt_weights.weights.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel weights saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnmt_weights.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/packed_distributed_variable.py:91\u001b[0m, in \u001b[0;36mPackedDistributedVariable.get_var_on_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m device:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_variables[i]\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not found\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m device)\n","\u001b[0;31mValueError\u001b[0m: Device /job:localhost/replica:0/task:0/device:CPU:0 is not found"],"ename":"ValueError","evalue":"Device /job:localhost/replica:0/task:0/device:CPU:0 is not found","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"# Step 12: Build the Inference Model\n\nwith strategy.scope():\n    # Encoder inference model\n    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n\n    # Decoder inference model\n    decoder_state_input_h = tf.keras.layers.Input(shape=(latent_dim,), name='decoder_state_input_h')\n    decoder_state_input_c = tf.keras.layers.Input(shape=(latent_dim,), name='decoder_state_input_c')\n    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n    dec_emb2 = dec_emb_layer(decoder_inputs)\n\n    decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n    decoder_states2 = [state_h2, state_c2]\n    decoder_outputs2 = decoder_dense(decoder_outputs2)\n\n    decoder_model = tf.keras.models.Model(\n        [decoder_inputs] + decoder_states_inputs,\n        [decoder_outputs2] + decoder_states2)\n\nprint(\"\\nInference models are ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:46:00.517180Z","iopub.execute_input":"2024-11-27T06:46:00.517590Z","iopub.status.idle":"2024-11-27T06:46:00.532693Z","shell.execute_reply.started":"2024-11-27T06:46:00.517555Z","shell.execute_reply":"2024-11-27T06:46:00.531591Z"}},"outputs":[{"name":"stdout","text":"\nInference models are ready.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Step 13: Define a Function to Decode Sequences\n\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1 with only the start token.\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = target_token_index.get('START_', 0)\n\n    # Sampling loop for a batch of sequences\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_word = reverse_target_token_index.get(sampled_token_index, '')\n\n        if sampled_word != '_END':\n            decoded_sentence += ' ' + sampled_word\n\n        # Exit condition: either hit max length or find stop token.\n        if (sampled_word == '_END' or len(decoded_sentence.split()) > max_length_tar):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence.strip()\n\nprint(\"\\nSequence decoding function is ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:46:03.971164Z","iopub.execute_input":"2024-11-27T06:46:03.972158Z","iopub.status.idle":"2024-11-27T06:46:03.979584Z","shell.execute_reply.started":"2024-11-27T06:46:03.972113Z","shell.execute_reply":"2024-11-27T06:46:03.978711Z"}},"outputs":[{"name":"stdout","text":"\nSequence decoding function is ready.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Step 14: Test the Model with Sample Sentences\n\nfor seq_index in range(5):\n    # Get the input sentence\n    input_seq = X_test_enc[seq_index: seq_index + 1]\n\n    # Decode the sequence to get the translated sentence\n    decoded_sentence = decode_sequence(input_seq)\n\n    # Get the actual TELUGU translation (remove START_ and _END tokens)\n    actual_translation = data['TELUGU'][X_train_enc.shape[0] + seq_index][7:-5]  # Adjust indices if necessary\n\n    print(f\"\\nInput Hindi sentence: {data['HINDI'][X_train_enc.shape[0] + seq_index]}\")\n    print(f\"Actual Telugu Translation: {actual_translation}\")\n    print(f\"Predicted Telugu Translation: {decoded_sentence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:46:11.472036Z","iopub.execute_input":"2024-11-27T06:46:11.472496Z","iopub.status.idle":"2024-11-27T06:46:31.043244Z","shell.execute_reply.started":"2024-11-27T06:46:11.472460Z","shell.execute_reply":"2024-11-27T06:46:31.042145Z"}},"outputs":[{"name":"stderr","text":"2024-11-27 06:46:12.378822: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node functional_1_1/encoder_embedding_1/GatherV2/ReadVariableOp.\nI0000 00:00:1732689972.472715   17468 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(1251be31d02d740d:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732689972.717095   17468 tpu_compile_op_common.cc:245] Compilation of 1251be31d02d740d:0:0 with session name  took 244.324371ms and succeeded\nI0000 00:00:1732689972.718422   17468 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(1251be31d02d740d:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_5018147358608534046\", property.function_library_fingerprint = 1710599553133815383, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,20,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732689972.718447   17468 tpu_compilation_cache_interface.cc:541] After adding entry for key 1251be31d02d740d:0:0 with session_name  cache is 5 entries (48543471 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1732689974.224206   17520 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(576d8e473c9da8c3:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732689974.512396   17520 tpu_compile_op_common.cc:245] Compilation of 576d8e473c9da8c3:0:0 with session name  took 288.149959ms and succeeded\nI0000 00:00:1732689974.514036   17520 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(576d8e473c9da8c3:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_7846581683446977397\", property.function_library_fingerprint = 4117562564988594661, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,1,;2,256,;2,256,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732689974.514082   17520 tpu_compilation_cache_interface.cc:541] After adding entry for key 576d8e473c9da8c3:0:0 with session_name  cache is 6 entries (49921086 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n\nInput Hindi sentence: श्रीलंकाई कप्तान नया है। दोनों की सारी उम्मीदें हैं\nActual Telugu Translation: లంక కెప్టెన్‌కూ కొత్తే ఆశలన్నీ వారిద్దరిపైనే\nPredicted Telugu Translation: ఆ అమ్మడు మళ్లీ సుష్మా స్వరాజ్\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976ms/step\n\nInput Hindi sentence: श्वसन और हृदय रोगियों को हर समय आईसीयू की आवश्यकता नहीं होती है\nActual Telugu Translation: శ్వాసకోశ హృద్రోగులకు అన్ని సార్లు ఐసీయూ అక్కర్లేదు\nPredicted Telugu Translation: వెంకీ సినిమాలో వెంకీ ఏంటి\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n\nInput Hindi sentence: हिमस्खलन में लोगों की मौत\nActual Telugu Translation: హిమపాతానికి మంది మృతి\nPredicted Telugu Translation: ఎయిరిండియా ఎయిర్‌ ఎయిర్‌కోస్టా సర్వీసులు\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n\nInput Hindi sentence: गुजरात किंग्स के लिए खिताब\nActual Telugu Translation: గుజరాత్ కింగ్స్‌కు టైటిల్‌\nPredicted Telugu Translation: అమ్మ ప్రేమకథ అక్కర్లేదు\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n\nInput Hindi sentence: दिल्ली एयरपोर्ट पर दिखे ड्रोन\nActual Telugu Translation: ఢిల్లీ విమానాశ్రయంలో డ్రోన్ల కలకలం\nPredicted Telugu Translation: కోహ్లీ విషయంలో కోహ్లీ\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}